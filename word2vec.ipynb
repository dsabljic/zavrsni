{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"papermill":{"duration":5153.845303,"end_time":"2020-12-17T15:07:09.130299","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2020-12-17T13:41:15.284996","version":"2.1.0"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Word2Vec","metadata":{"id":"EoYwsFI05N8L"}},{"cell_type":"code","source":"!conda install -y gdown","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k5TmLwMku9xL","outputId":"8abe7fc9-04a8-4d13-e9e0-8dc551d68100","execution":{"iopub.status.busy":"2024-08-31T12:25:34.894126Z","iopub.execute_input":"2024-08-31T12:25:34.894416Z","iopub.status.idle":"2024-08-31T12:27:06.086786Z","shell.execute_reply.started":"2024-08-31T12:25:34.894392Z","shell.execute_reply":"2024-08-31T12:27:06.085907Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Retrieving notices: ...working... done\nChannels:\n - rapidsai\n - nvidia\n - conda-forge\n - defaults\n - pytorch\nPlatform: linux-64\nCollecting package metadata (repodata.json): done\nSolving environment: done\n\n## Package Plan ##\n\n  environment location: /opt/conda\n\n  added / updated specs:\n    - gdown\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    ca-certificates-2024.8.30  |       hbcca054_0         155 KB  conda-forge\n    conda-24.7.1               |  py310hff52083_0         940 KB  conda-forge\n    filelock-3.15.4            |     pyhd8ed1ab_0          17 KB  conda-forge\n    gdown-5.2.0                |     pyhd8ed1ab_0          21 KB  conda-forge\n    openssl-3.3.1              |       hb9d3cd8_3         2.8 MB  conda-forge\n    ------------------------------------------------------------\n                                           Total:         3.9 MB\n\nThe following NEW packages will be INSTALLED:\n\n  filelock           conda-forge/noarch::filelock-3.15.4-pyhd8ed1ab_0 \n  gdown              conda-forge/noarch::gdown-5.2.0-pyhd8ed1ab_0 \n\nThe following packages will be UPDATED:\n\n  ca-certificates                       2024.7.4-hbcca054_0 --> 2024.8.30-hbcca054_0 \n  conda                              24.5.0-py310hff52083_0 --> 24.7.1-py310hff52083_0 \n  openssl                                  3.3.1-h4ab18f5_1 --> 3.3.1-hb9d3cd8_3 \n\n\n\nDownloading and Extracting Packages:\nopenssl-3.3.1        | 2.8 MB    |                                       |   0% \nconda-24.7.1         | 940 KB    |                                       |   0% \u001b[A\n\nca-certificates-2024 | 155 KB    |                                       |   0% \u001b[A\u001b[A\n\n\ngdown-5.2.0          | 21 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\n\n\n\nfilelock-3.15.4      | 17 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\nconda-24.7.1         | 940 KB    | 6                                     |   2% \u001b[A\n\nopenssl-3.3.1        | 2.8 MB    | 2                                     |   1% \u001b[A\u001b[A\n\n\ngdown-5.2.0          | 21 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n\n\ngdown-5.2.0          | 21 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n\n\n\nfilelock-3.15.4      | 17 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\nfilelock-3.15.4      | 17 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n\nopenssl-3.3.1        | 2.8 MB    | ##################################### | 100% \u001b[A\u001b[A\nconda-24.7.1         | 940 KB    | ##################################### | 100% \u001b[A\n                                                                                \u001b[A\n                                                                                \u001b[A\n\n                                                                                \u001b[A\u001b[A\n\n\n                                                                                \u001b[A\u001b[A\u001b[A\n\n\n\n                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\nPreparing transaction: done\nVerifying transaction: done\nExecuting transaction: done\n","output_type":"stream"}]},{"cell_type":"code","source":"!gdown 1ihU82zD5LKm8KvgvpSYM_32LC841MFGG","metadata":{"execution":{"iopub.status.busy":"2024-08-31T12:27:06.088177Z","iopub.execute_input":"2024-08-31T12:27:06.088539Z","iopub.status.idle":"2024-08-31T12:27:13.330674Z","shell.execute_reply.started":"2024-08-31T12:27:06.088504Z","shell.execute_reply":"2024-08-31T12:27:13.329634Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Downloading...\nFrom: https://drive.google.com/uc?id=1ihU82zD5LKm8KvgvpSYM_32LC841MFGG\nTo: /kaggle/working/balanced_yelp_reviews.csv\n100%|███████████████████████████████████████| 95.8M/95.8M [00:00<00:00, 102MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"file_path = './balanced_yelp_reviews.csv'","metadata":{"id":"Ivo2jWo_vj1D","execution":{"iopub.status.busy":"2024-08-31T12:27:13.332201Z","iopub.execute_input":"2024-08-31T12:27:13.332525Z","iopub.status.idle":"2024-08-31T12:27:13.337059Z","shell.execute_reply.started":"2024-08-31T12:27:13.332496Z","shell.execute_reply":"2024-08-31T12:27:13.336061Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport time\nimport datetime\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import classification_report, accuracy_score\n\nfrom gensim.utils import tokenize\nfrom gensim.parsing.porter import PorterStemmer\nfrom gensim.models import Word2Vec","metadata":{"execution":{"iopub.status.busy":"2024-08-31T12:27:13.339420Z","iopub.execute_input":"2024-08-31T12:27:13.339740Z","iopub.status.idle":"2024-08-31T12:27:29.050140Z","shell.execute_reply.started":"2024-08-31T12:27:13.339690Z","shell.execute_reply":"2024-08-31T12:27:29.049394Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"VECTOR_SIZE = 500\nWINDOW = 5\nMIN_COUNT = 10\nWORKERS = 3\nSG = 1\n\nBATCH_SIZE = 32\nNUM_EPOCHS = 15\nLEARNING_RATE = 1e-3\nPATIENCE = 3\nDROPOUT_RATE = 0.5","metadata":{"execution":{"iopub.status.busy":"2024-08-31T12:27:29.051122Z","iopub.execute_input":"2024-08-31T12:27:29.052034Z","iopub.status.idle":"2024-08-31T12:27:29.056770Z","shell.execute_reply.started":"2024-08-31T12:27:29.052008Z","shell.execute_reply":"2024-08-31T12:27:29.055817Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"statement_df = pd.read_csv(file_path)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T12:27:29.057835Z","iopub.execute_input":"2024-08-31T12:27:29.058087Z","iopub.status.idle":"2024-08-31T12:27:30.109797Z","shell.execute_reply.started":"2024-08-31T12:27:29.058065Z","shell.execute_reply":"2024-08-31T12:27:30.108646Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"statement_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-31T12:27:30.111110Z","iopub.execute_input":"2024-08-31T12:27:30.111410Z","iopub.status.idle":"2024-08-31T12:27:30.129475Z","shell.execute_reply.started":"2024-08-31T12:27:30.111386Z","shell.execute_reply":"2024-08-31T12:27:30.128589Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                           statement sentiment\n0  My wife and I were down town for a show and we...   neutral\n1  My friends and I had a craving for fried chick...  negative\n2  They have very nice tiles and displays, but th...  negative\n3  THE ABSOLUTE WORST! They pretty much charged u...  negative\n4  The restaurant by itself was so cute but the b...   neutral","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>statement</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>My wife and I were down town for a show and we...</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>My friends and I had a craving for fried chick...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>They have very nice tiles and displays, but th...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>THE ABSOLUTE WORST! They pretty much charged u...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The restaurant by itself was so cute but the b...</td>\n      <td>neutral</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"statement_df['tokenized_text'] = [list(tokenize(line, lowercase=False, deacc=True)) for line in statement_df['statement']]\n\ndef stem_preserving_case(word):\n    porter_stemmer = PorterStemmer()\n    stemmed_word = porter_stemmer.stem(word.lower())\n    if word.isupper():\n        return stemmed_word.upper()\n    elif word[0].isupper():\n        return stemmed_word.capitalize()\n    else:\n        return stemmed_word\n    \n# porter_stemmer = PorterStemmer()\n# statement_df['stemmed_tokens'] = [[porter_stemmer.stem(word) for word in tokens] for tokens in statement_df['tokenized_text']]\nstatement_df['stemmed_tokens'] = [[stem_preserving_case(word) for word in tokens] for tokens in statement_df['tokenized_text']]\n\nle = LabelEncoder()\nstatement_df['sentiment'] = le.fit_transform(statement_df['sentiment'])","metadata":{"execution":{"iopub.status.busy":"2024-08-31T12:27:30.131101Z","iopub.execute_input":"2024-08-31T12:27:30.131486Z","iopub.status.idle":"2024-08-31T12:30:50.447571Z","shell.execute_reply.started":"2024-08-31T12:27:30.131451Z","shell.execute_reply":"2024-08-31T12:30:50.446808Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"statement_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-31T12:30:50.448743Z","iopub.execute_input":"2024-08-31T12:30:50.449088Z","iopub.status.idle":"2024-08-31T12:30:50.467959Z","shell.execute_reply.started":"2024-08-31T12:30:50.449057Z","shell.execute_reply":"2024-08-31T12:30:50.466980Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                                           statement  sentiment  \\\n0  My wife and I were down town for a show and we...          1   \n1  My friends and I had a craving for fried chick...          0   \n2  They have very nice tiles and displays, but th...          0   \n3  THE ABSOLUTE WORST! They pretty much charged u...          0   \n4  The restaurant by itself was so cute but the b...          1   \n\n                                      tokenized_text  \\\n0  [My, wife, and, I, were, down, town, for, a, s...   \n1  [My, friends, and, I, had, a, craving, for, fr...   \n2  [They, have, very, nice, tiles, and, displays,...   \n3  [THE, ABSOLUTE, WORST, They, pretty, much, cha...   \n4  [The, restaurant, by, itself, was, so, cute, b...   \n\n                                      stemmed_tokens  \n0  [My, wife, and, I, were, down, town, for, a, s...  \n1  [My, friend, and, I, had, a, crave, for, fri, ...  \n2  [Thei, have, veri, nice, tile, and, displai, b...  \n3  [THE, ABSOLUT, WORST, Thei, pretti, much, char...  \n4  [The, restaur, by, itself, wa, so, cute, but, ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>statement</th>\n      <th>sentiment</th>\n      <th>tokenized_text</th>\n      <th>stemmed_tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>My wife and I were down town for a show and we...</td>\n      <td>1</td>\n      <td>[My, wife, and, I, were, down, town, for, a, s...</td>\n      <td>[My, wife, and, I, were, down, town, for, a, s...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>My friends and I had a craving for fried chick...</td>\n      <td>0</td>\n      <td>[My, friends, and, I, had, a, craving, for, fr...</td>\n      <td>[My, friend, and, I, had, a, crave, for, fri, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>They have very nice tiles and displays, but th...</td>\n      <td>0</td>\n      <td>[They, have, very, nice, tiles, and, displays,...</td>\n      <td>[Thei, have, veri, nice, tile, and, displai, b...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>THE ABSOLUTE WORST! They pretty much charged u...</td>\n      <td>0</td>\n      <td>[THE, ABSOLUTE, WORST, They, pretty, much, cha...</td>\n      <td>[THE, ABSOLUT, WORST, Thei, pretti, much, char...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The restaurant by itself was so cute but the b...</td>\n      <td>1</td>\n      <td>[The, restaurant, by, itself, was, so, cute, b...</td>\n      <td>[The, restaur, by, itself, wa, so, cute, but, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"X_train, X_test, Y_train, Y_test = train_test_split(statement_df[['statement', 'stemmed_tokens']],\n                                                    statement_df['sentiment'],\n                                                    shuffle=True,\n                                                    test_size=0.2,\n                                                    random_state=15)\n\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train,\n                                                  shuffle=True,\n                                                  test_size=0.25,\n                                                  random_state=15)\n\nX_train = X_train.reset_index(drop=True)\nX_val = X_val.reset_index(drop=True)\nX_test = X_test.reset_index(drop=True)\nY_train = Y_train.to_frame().reset_index(drop=True)\nY_val = Y_val.to_frame().reset_index(drop=True)\nY_test = Y_test.to_frame().reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T12:30:50.469077Z","iopub.execute_input":"2024-08-31T12:30:50.469376Z","iopub.status.idle":"2024-08-31T12:30:50.587472Z","shell.execute_reply.started":"2024-08-31T12:30:50.469353Z","shell.execute_reply":"2024-08-31T12:30:50.586727Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def format_time(elapsed):\n    return str(datetime.timedelta(seconds=int(round(elapsed))))","metadata":{"execution":{"iopub.status.busy":"2024-08-31T12:30:50.588530Z","iopub.execute_input":"2024-08-31T12:30:50.588818Z","iopub.status.idle":"2024-08-31T12:30:50.593824Z","shell.execute_reply.started":"2024-08-31T12:30:50.588793Z","shell.execute_reply":"2024-08-31T12:30:50.592867Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"start = time.time()\n\nstemmed_tokens = pd.Series(X_train['stemmed_tokens']).values\nw2v_model = Word2Vec(stemmed_tokens, min_count=MIN_COUNT, vector_size=VECTOR_SIZE, workers=WORKERS, window=WINDOW, sg=SG)\n\nprint(format_time(time.time() - start))\n\nword2vec_model_file = 'word2vec_' + str(VECTOR_SIZE) + '.model'\nw2v_model.save(word2vec_model_file)\nsg_w2v_model = Word2Vec.load(word2vec_model_file)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T12:30:50.596827Z","iopub.execute_input":"2024-08-31T12:30:50.597138Z","iopub.status.idle":"2024-08-31T12:35:01.203927Z","shell.execute_reply.started":"2024-08-31T12:30:50.597110Z","shell.execute_reply":"2024-08-31T12:35:01.203107Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"0:04:10\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_mean_feature_vector(data, model, vector_size):\n    features = []\n    for tokens in data:\n        vectors = [model.wv[token] for token in tokens if token in model.wv]\n        if len(vectors) > 0:\n            mean_vector = np.mean(vectors, axis=0)\n        else:\n            mean_vector = np.zeros(vector_size)\n        features.append(mean_vector)\n    return np.array(features)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T12:35:01.205268Z","iopub.execute_input":"2024-08-31T12:35:01.205581Z","iopub.status.idle":"2024-08-31T12:35:01.211730Z","shell.execute_reply.started":"2024-08-31T12:35:01.205553Z","shell.execute_reply":"2024-08-31T12:35:01.210905Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"X_train_vec = get_mean_feature_vector(X_train['stemmed_tokens'], sg_w2v_model, VECTOR_SIZE)\nX_val_vec = get_mean_feature_vector(X_val['stemmed_tokens'], sg_w2v_model, VECTOR_SIZE)\nX_test_vec = get_mean_feature_vector(X_test['stemmed_tokens'], sg_w2v_model, VECTOR_SIZE)\n\nX_train_tensor = torch.tensor(X_train_vec, dtype=torch.float32)\nY_train_tensor = torch.tensor(Y_train['sentiment'].values, dtype=torch.long)\nX_val_tensor = torch.tensor(X_val_vec, dtype=torch.float32)\nY_val_tensor = torch.tensor(Y_val['sentiment'].values, dtype=torch.long)\nX_test_tensor = torch.tensor(X_test_vec, dtype=torch.float32)\nY_test_tensor = torch.tensor(Y_test['sentiment'].values, dtype=torch.long)\n\ntrain_dataset = TensorDataset(X_train_tensor, Y_train_tensor)\nval_dataset = TensorDataset(X_val_tensor, Y_val_tensor)\ntest_dataset = TensorDataset(X_test_tensor, Y_test_tensor)\n\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T12:35:01.212968Z","iopub.execute_input":"2024-08-31T12:35:01.213292Z","iopub.status.idle":"2024-08-31T12:36:09.440735Z","shell.execute_reply.started":"2024-08-31T12:35:01.213268Z","shell.execute_reply":"2024-08-31T12:36:09.439741Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"class SimpleNN(nn.Module):\n    def __init__(self, input_size, num_classes):\n        super(SimpleNN, self).__init__()\n        self.fc1 = nn.Linear(input_size, 128)\n        self.fc2 = nn.Linear(128, 64)\n        self.fc3 = nn.Linear(64, 32)\n        self.fc4 = nn.Linear(32, num_classes)\n        self.dropout = nn.Dropout(0.3)\n\n    def forward(self, x):\n        x = torch.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = torch.relu(self.fc2(x))\n        x = self.dropout(x)\n        x = torch.relu(self.fc3(x))\n        x = self.fc4(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-08-31T12:36:09.442049Z","iopub.execute_input":"2024-08-31T12:36:09.443978Z","iopub.status.idle":"2024-08-31T12:36:09.451492Z","shell.execute_reply.started":"2024-08-31T12:36:09.443945Z","shell.execute_reply":"2024-08-31T12:36:09.450594Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"input_size = VECTOR_SIZE\nnum_classes = len(le.classes_)\nmodel = SimpleNN(input_size, num_classes)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\n\nbest_val_loss = float('inf')\nearly_stopping_counter = 0\nbest_model_path = 'best_model.pth'\n\nstart_time = time.time()\n\nfor epoch in range(NUM_EPOCHS):\n    epoch_start_time = time.time()\n    \n    print(f\"\\nEpoch {epoch + 1} / {NUM_EPOCHS}\")\n    print(\"-\" * 50)\n    \n    model.train()\n    train_loss = 0\n    correct_train = 0\n    total_train = 0\n\n    for X_batch, Y_batch in train_loader:\n        X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(X_batch)\n        loss = criterion(outputs, Y_batch)\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n\n        _, predicted = torch.max(outputs.data, 1)\n        total_train += Y_batch.size(0)\n        correct_train += (predicted == Y_batch).sum().item()\n\n    train_accuracy = correct_train / total_train\n\n    model.eval()\n    val_loss = 0\n    correct_val = 0\n    total_val = 0\n    all_val_preds = []\n    all_val_labels = []\n\n    with torch.no_grad():\n        for X_batch, Y_batch in val_loader:\n            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n\n            outputs = model(X_batch)\n            loss = criterion(outputs, Y_batch)\n            val_loss += loss.item()\n\n            _, predicted = torch.max(outputs.data, 1)\n            total_val += Y_batch.size(0)\n            correct_val += (predicted == Y_batch).sum().item()\n\n            all_val_preds.extend(predicted.cpu().numpy())\n            all_val_labels.extend(Y_batch.cpu().numpy())\n\n    val_accuracy = correct_val / total_val\n    \n    print(f\"Train Loss: {train_loss / len(train_loader)} | Train Accuracy: {train_accuracy}\")\n    print(f\"Val Loss: {val_loss / len(val_loader)} | Val Accuracy: {val_accuracy}\\n\")\n    print(f'Epoch Train Time: {format_time(time.time() - epoch_start_time)}')\n    print('\\n')\n\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        early_stopping_counter = 0\n        torch.save(model.state_dict(), best_model_path)\n        print(\"Saved best model\")\n    else:\n        early_stopping_counter += 1\n        if early_stopping_counter >= PATIENCE:\n            print(\"Early stopping triggered\")\n            break\nprint('Finished Training.')\nprint(f'Fold Train Time: {format_time(time.time() - start_time)}')\nprint('\\n')","metadata":{"execution":{"iopub.status.busy":"2024-08-31T12:36:09.452764Z","iopub.execute_input":"2024-08-31T12:36:09.453047Z","iopub.status.idle":"2024-08-31T12:37:59.079756Z","shell.execute_reply.started":"2024-08-31T12:36:09.453022Z","shell.execute_reply":"2024-08-31T12:37:59.078790Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"\nEpoch 1 / 15\n--------------------------------------------------\nTrain Loss: 0.6490584009913334 | Train Accuracy: 0.7146222222222223\nVal Loss: 0.5701985127095983 | Val Accuracy: 0.7597\n\nEpoch Train Time: 0:00:08\n\n\nSaved best model\n\nEpoch 2 / 15\n--------------------------------------------------\nTrain Loss: 0.5904728404533978 | Train Accuracy: 0.7496666666666667\nVal Loss: 0.6025833055408779 | Val Accuracy: 0.7393\n\nEpoch Train Time: 0:00:07\n\n\n\nEpoch 3 / 15\n--------------------------------------------------\nTrain Loss: 0.5817115993271762 | Train Accuracy: 0.7530333333333333\nVal Loss: 0.5633497564777382 | Val Accuracy: 0.7567666666666667\n\nEpoch Train Time: 0:00:07\n\n\nSaved best model\n\nEpoch 4 / 15\n--------------------------------------------------\nTrain Loss: 0.576572515968322 | Train Accuracy: 0.7548\nVal Loss: 0.5821544419028866 | Val Accuracy: 0.7488666666666667\n\nEpoch Train Time: 0:00:07\n\n\n\nEpoch 5 / 15\n--------------------------------------------------\nTrain Loss: 0.5695277075516639 | Train Accuracy: 0.7577333333333334\nVal Loss: 0.5557263922303725 | Val Accuracy: 0.7614\n\nEpoch Train Time: 0:00:07\n\n\nSaved best model\n\nEpoch 6 / 15\n--------------------------------------------------\nTrain Loss: 0.5664695138624881 | Train Accuracy: 0.7584333333333333\nVal Loss: 0.5627907670414778 | Val Accuracy: 0.7616\n\nEpoch Train Time: 0:00:07\n\n\n\nEpoch 7 / 15\n--------------------------------------------------\nTrain Loss: 0.5623765986212792 | Train Accuracy: 0.7599888888888889\nVal Loss: 0.5554092457807903 | Val Accuracy: 0.7632\n\nEpoch Train Time: 0:00:07\n\n\nSaved best model\n\nEpoch 8 / 15\n--------------------------------------------------\nTrain Loss: 0.5604420392550568 | Train Accuracy: 0.7605666666666666\nVal Loss: 0.5589372863742843 | Val Accuracy: 0.7600666666666667\n\nEpoch Train Time: 0:00:07\n\n\n\nEpoch 9 / 15\n--------------------------------------------------\nTrain Loss: 0.5584063605507031 | Train Accuracy: 0.7612\nVal Loss: 0.5512737501849497 | Val Accuracy: 0.7627\n\nEpoch Train Time: 0:00:07\n\n\nSaved best model\n\nEpoch 10 / 15\n--------------------------------------------------\nTrain Loss: 0.5555791661243951 | Train Accuracy: 0.7647111111111111\nVal Loss: 0.5511887742003907 | Val Accuracy: 0.7614\n\nEpoch Train Time: 0:00:07\n\n\nSaved best model\n\nEpoch 11 / 15\n--------------------------------------------------\nTrain Loss: 0.5545394454844007 | Train Accuracy: 0.7629\nVal Loss: 0.5501428328946963 | Val Accuracy: 0.7606\n\nEpoch Train Time: 0:00:07\n\n\nSaved best model\n\nEpoch 12 / 15\n--------------------------------------------------\nTrain Loss: 0.5520887005818598 | Train Accuracy: 0.7636777777777778\nVal Loss: 0.5487351555273985 | Val Accuracy: 0.7663\n\nEpoch Train Time: 0:00:07\n\n\nSaved best model\n\nEpoch 13 / 15\n--------------------------------------------------\nTrain Loss: 0.5506362894697626 | Train Accuracy: 0.7644111111111112\nVal Loss: 0.5484959144455029 | Val Accuracy: 0.7655666666666666\n\nEpoch Train Time: 0:00:07\n\n\nSaved best model\n\nEpoch 14 / 15\n--------------------------------------------------\nTrain Loss: 0.5487332008898237 | Train Accuracy: 0.7666777777777778\nVal Loss: 0.5415552213057272 | Val Accuracy: 0.7666666666666667\n\nEpoch Train Time: 0:00:07\n\n\nSaved best model\n\nEpoch 15 / 15\n--------------------------------------------------\nTrain Loss: 0.5465983426469185 | Train Accuracy: 0.7654111111111112\nVal Loss: 0.5433644805667497 | Val Accuracy: 0.7654\n\nEpoch Train Time: 0:00:07\n\n\nFinished Training.\nFold Train Time: 0:01:48\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"model.load_state_dict(torch.load(best_model_path))\n\nmodel.eval()\n\nprint(\"Classification Report on Validation Set:\")\nprint(classification_report(all_val_labels, all_val_preds, target_names=le.classes_))","metadata":{"execution":{"iopub.status.busy":"2024-08-31T12:37:59.081034Z","iopub.execute_input":"2024-08-31T12:37:59.081390Z","iopub.status.idle":"2024-08-31T12:37:59.121802Z","shell.execute_reply.started":"2024-08-31T12:37:59.081355Z","shell.execute_reply":"2024-08-31T12:37:59.120938Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Classification Report on Validation Set:\n              precision    recall  f1-score   support\n\n    negative       0.78      0.83      0.81      9890\n     neutral       0.68      0.67      0.67     10114\n    positive       0.84      0.80      0.82      9996\n\n    accuracy                           0.77     30000\n   macro avg       0.77      0.77      0.77     30000\nweighted avg       0.77      0.77      0.77     30000\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Test set evaluation (generalization error)","metadata":{}},{"cell_type":"code","source":"model.eval()\nall_preds = []\nall_labels = []\n\nwith torch.no_grad():\n    for X_batch, Y_batch in test_loader:\n        X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n\n        outputs = model(X_batch)\n        _, predicted = torch.max(outputs.data, 1)\n\n        all_preds.extend(predicted.cpu().numpy())\n        all_labels.extend(Y_batch.cpu().numpy())\n\ntest_accuracy = accuracy_score(all_labels, all_preds)\nprint(f'Test Accuracy: {test_accuracy:.2f}')\n\nprint(\"\\nClassification Report:\")\nprint(classification_report(all_labels, all_preds, target_names=le.classes_))","metadata":{"execution":{"iopub.status.busy":"2024-08-31T12:57:33.044492Z","iopub.execute_input":"2024-08-31T12:57:33.044896Z","iopub.status.idle":"2024-08-31T12:57:33.795565Z","shell.execute_reply.started":"2024-08-31T12:57:33.044864Z","shell.execute_reply":"2024-08-31T12:57:33.794649Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Test Accuracy: 0.77\n\nClassification Report:\n              precision    recall  f1-score   support\n\n    negative       0.82      0.78      0.80      9948\n     neutral       0.67      0.71      0.69     10136\n    positive       0.83      0.82      0.82      9916\n\n    accuracy                           0.77     30000\n   macro avg       0.77      0.77      0.77     30000\nweighted avg       0.77      0.77      0.77     30000\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}